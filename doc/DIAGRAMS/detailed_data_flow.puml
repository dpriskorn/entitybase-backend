@startuml detailed_data_flow

title Complete Data Flow: Entity Creation → RDF Change Event
note right
  Generated from Wikibase Backend codebase
  Shows only internal components
end note

' Entry Points
package "REST API Layer" #LightBlue {
    component [Entity Endpoints\n/entities/{id}] as API
    note right of API: POST, PATCH, DELETE\nsrc/models/rest_api/entitybase/v1/endpoints/entities.py
}

' Processing
package "Entity Processing" #LightGreen {
    component [Request Validation\n_validate_revision_request] as VALIDATE
    component [Idempotency Check\n_check_idempotency_new] as IDEMPOTENT
    component [Entity Processing\n_process_entity_data_new] as PROCESS
    component [Hashing & Dedup\nEntityHashingService] as HASH
}

' Storage
package "Storage Layer" #LightYellow {
    database "Vitess Repository\n(Revision Metadata)" as DB
    note right of DB: src/models/infrastructure/vitess/repositories/revision.py

    storage "S3 Client\n(Full Snapshots)" as S3
    note right of S3: src/models/infrastructure/s3/client.py
}

' Event Publishing Step 1
queue "Kafka/Redpanda\nentitybase.entity_change" as KAFKA1
note right of KAFKA1: EntityChangeEvent\nsrc/models/infrastructure/stream/event.py

' Legacy Entity Diff Worker (RDF canonicalization + full diff)
package "Entity Diff Worker (Legacy)" #Lavender {
    component [Entity Diff Worker] as WORKER
    note right of WORKER: src/models/workers/entity_diff/entity_diff_worker.py

    component [RDF Serializer] as RDF_CONV
    note right of RDF_CONV: entity_data_to_rdf()

    component [RDF Canonicalizer\nURDNA2015] as CANONICAL
    note right of CANONICAL: src/models/workers/entity_diff/rdf_cannonicalizer.py

    component [Diff Computation\nAdded/Removed Triples] as DIFF
}

' Event Publishing Step 2 (Legacy)
queue "Kafka/Redpanda\nwikibase.entity_diff" as KAFKA2
note right of KAFKA2: RDFChangeEvent\nadded_triples, removed_triples

' New Incremental RDF Worker (Diff-based updates)
package "Incremental RDF Worker" #LightCyan {
    component [IncrementalRDFWorker] as INCR_WORKER
    note right of INCR_WORKER: src/models/workers/incremental_rdf/incremental_rdf_worker.py

    component [IncrementalRDFUpdater] as INCR_UPDATER
    note right of INCR_UPDATER: src/models/rdf_builder/incremental_updater.py

    component [RDF Change Builder] as RDF_BUILD
    note right of RDF_BUILD: entity_diff/2.0.0 schema
}

' Event Publishing Step 2 (Incremental)
queue "Kafka/Redpanda\nincremental_rdf_diff" as KAFKA3
note right of KAFKA3: RDFChangeEvent\nrdf_added_data, rdf_deleted_data\n(entity_diff/2.0.0)

' Internal Consumer
package "Internal Consumers" #Coral {
    component [Watchlist Consumer] as WATCHLIST
    note right of WATCHLIST: src/models/workers/watchlist_consumer/main.py
}

' Data Flow Connections
API --> VALIDATE : 1. HTTP Request
VALIDATE --> IDEMPOTENT : 2. Validated
IDEMPOTENT --> PROCESS : 3. Unique request
PROCESS --> HASH : 4. Processed data
HASH --> DB : 5a. Revision metadata
HASH --> S3 : 5b. Full snapshot

DB --> KAFKA1 : 6a. Trigger
S3 --> KAFKA1 : 6b. Trigger

' Legacy worker flow
KAFKA1 --> WORKER : 7. EntityChangeEvent
WORKER --> RDF_CONV : 8. JSON → Turtle
RDF_CONV --> CANONICAL : 9. Canonicalize
CANONICAL --> DIFF : 10. Normalized triples
DIFF --> KAFKA2 : 11. RDFChangeEvent

' Incremental worker flow
KAFKA1 --> INCR_WORKER : 7b. EntityChangeEvent
INCR_WORKER --> S3 : 8b. Fetch entity snapshots
INCR_WORKER --> INCR_UPDATER : 9b. Compute diffs
INCR_UPDATER --> RDF_BUILD : 10b. Build RDF event
RDF_BUILD --> KAFKA3 : 11b. RDFChangeEvent\n(entity_diff/2.0.0)

KAFKA1 --> WATCHLIST : 12. EntityChangeEvent

note bottom of KAFKA2
  Legacy RDF diff flow:
  • Full RDF canonicalization
  • wikibase.entity_diff topic
  • Used by WDQS, search indexers
end note

note bottom of KAFKA3
  Incremental RDF diff flow:
  • Diff-based updates
  • incremental_rdf_diff topic
  • entity_diff/2.0.0 schema
  • Lower overhead, faster processing
end note

@enduml
